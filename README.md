# Ollama Chatbot

A feature-rich chatbot interface built with Gradio and LangChain for interacting with Ollama models.

## Requirements

- Python 3.8+
- Ollama running locally

## Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Optional: Create a .env file from the example
cp .env.example .env
```

## Usage

```bash
python run.py
```

The application will start on `http://localhost:7860`

## Features

### Core Features
- ğŸ¤– **Chat with local Ollama models** - Full conversation interface
- ğŸ›ï¸ **Custom system prompts** - Define assistant behavior and personality
- ğŸ”„ **Dynamic model loading** - Automatically fetch available models from Ollama
- ğŸ“‹ **Model selection** - Choose from available local models
- ğŸ’¬ **Conversation history** - Maintain chat context

### Advanced Features
- âš¡ **LLM instance caching** âœ… - Improved performance with cached model instances
- ğŸ”„ **Model refresh** âœ… - Manual refresh of available models
- ğŸ§¹ **Cache management** âœ… - Clear cache when needed
- ğŸ›¡ï¸ **Input sanitization** âœ… - Basic security for user inputs
- ğŸ“Š **Model information** âœ… - Detailed model info and capabilities
- ğŸ’¾ **System prompt persistence** âœ… - Save and load system prompts between sessions
- ğŸ’¬ **Conversation history persistence** âœ… - Save and load chat conversations

### UI/UX Enhancements
- ğŸ¨ **Loading indicators** âœ… - Visual feedback during model responses
- ğŸ“± **Responsive design** âœ… - Works on different screen sizes
- ğŸ”„ **Real-time updates** âœ… - Model info updates automatically
- ğŸ¯ **Error handling** âœ… - User-friendly error messages
- ğŸ“‹ **Sidebar reorganization** âœ… - Cleaner layout with better organization

### Upcoming Features
- ğŸ’¬ **Conversation history persistence** - Save and load chat conversations
- â±ï¸ **Rate limiting** - Prevent abuse and manage resources
- âš™ï¸ **Model parameter controls** - Adjust temperature, top_p, etc.
- ğŸ‘¥ **Multi-user support** - Multiple users and sessions
- ğŸ” **Authentication** - Secure access to the application

## Configuration

The application supports configuration via environment variables or `.env` file:

```env
# Ollama Server Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=120

# Application Configuration
APP_TITLE="Ollama Chat"
APP_DESCRIPTION="A sleek interface for local LLM conversations"
CHAT_HEIGHT=550
MAX_MESSAGE_LENGTH=10000
MAX_SYSTEM_PROMPT_LENGTH=5000

# Cache Configuration
CACHE_SIZE=100
CACHE_TTL=3600
```

## Development

### Testing

```bash
pytest tests/
```

### Code Quality

```bash
# Format code
black src/

# Sort imports
isort src/

# Type checking
mypy src/

# Linting
ruff check src/
```

## Architecture

- **Config Management**: Pydantic-based settings with environment variable support
- **Caching**: LLM instance and response caching for performance
- **Error Handling**: Comprehensive error handling and user feedback
- **Security**: Input sanitization and validation
- **UI**: Gradio-based responsive interface

## Roadmap

### âœ… Completed
- [x] Add comprehensive configuration system with .env support
- [x] Implement dynamic model loading from Ollama API
- [x] Add LLM instance caching for better performance
- [x] Enhance error handling and user feedback
- [x] Add loading indicators and UI improvements
- [x] Implement system prompt persistence
- [x] Reorganize sidebar for better UX
- [x] Add conversation history persistence

### ğŸš€ In Progress
- [ ] Add conversation search and filtering
- [ ] Implement export/import functionality
- [ ] Add model parameter controls (temperature, top_p, etc.)
- [ ] Implement rate limiting
=======
### âœ… Completed
- [x] Add comprehensive configuration system with .env support
- [x] Implement dynamic model loading from Ollama API
- [x] Add LLM instance caching for better performance
- [x] Enhance error handling and user feedback
- [x] Add loading indicators and UI improvements
- [x] Implement system prompt persistence
- [x] Reorganize sidebar for better UX
- [x] Add conversation history persistence

### ğŸš€ In Progress
- [ ] Add conversation search and filtering
- [ ] Implement export/import functionality
- [ ] Add model parameter controls (temperature, top_p, etc.)
- [ ] Implement rate limiting
=======
### âœ… Completed
- [x] Add conversation history persistence
- [x] Implement rate limiting
- [x] Add model parameter controls (temperature, top_p, etc.)

### ğŸš€ In Progress
- [ ] Add conversation search and filtering
- [ ] Implement export/import functionality

### ğŸ“‹ Planned
- [ ] Support for multiple users/sessions
- [ ] Add authentication
- [ ] Implement model downloading/pulling
- [ ] Add model performance metrics
- [ ] Add conversation search and filtering
- [ ] Implement export/import functionality
